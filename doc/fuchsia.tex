\documentclass[12pt,a4paper]{article}

\usepackage{amssymb,amsmath,color,enumitem,fancyvrb,hyperref,xspace}
\usepackage[affil-it]{authblk}

\bibliographystyle{alphaurl}
%\bibliographystyle{JHEP}

\setcounter{tocdepth}{2}
\fvset{fontsize=\small,commandchars=\\\{\}}

\definecolor{fuchsia}{RGB}{236,0,140}
\definecolor{prompt}{RGB}{245,124,0}
\definecolor{command}{RGB}{48,63,159}

\hypersetup{
    colorlinks,
    urlcolor={fuchsia},
    citecolor={blue}
}

\input include/commands.tex

\input include/layout.tex
\input include/title.tex

\begin{document}

\maketitle
\thispagestyle{empty}

\begin{abstract}
We present \fuchsia: a tool and a library implementing Lee's algorithm \cite{Lee15} which, given an ODE system with rational function coefficients $\partial_x \V J = \M A(x,\eps)\,\V J$, constructs an equivalent system of the form $\partial_x \V J' = \eps\,\M S(x)\,\V J'$ and corresponding basis transformation $\V J = \M T(x,\eps)\,\V J'$.
After and if such a reduction is successfully done the system can be trivially solved, which makes a reduction step crucial to obtain the solution.

In principle, \fuchsia can deal with any regular systems, however it's primary task is to reduce differential equations for master integrals which arise from Feynman diagrams.
It ensures that solutions contain regular singularities only due to the analyticity of S-matrix.

We discuss limitations and possible extensions of the proposed implementation.
\end{abstract}
\newpage

\input include/summary.tex
\newpage

\tableofcontents

\section{Introduction}

More than 60 years has passed since Richard Feynman proposed a diagrammatic approach for calculating perturbative processes in quantum field theories.
Since then Feynman integrals calculus has grown to a separate branch of the mathematical physics with a big community of scientists making research in this exciting field.
With no doubt we can say that none of the recent discoveries in the high-energy particle physics could happen without precise theoretical calculations, which are based on the Feynman integrals calculation techniques. 
It is also clear that such techniques will play a key role for discoveries at the present and future high-energy colliders, hence their development and further improvement are very important task.

Recent progress in computational techniques made possible to automate calculation of Feynman integrals; problems which seemed impossible 10 years ago now are successfully solved with state-of-the-art computer algorithms.
Among the most popular are integration-by-parts (IBP) reduction~\cite{CT81} and the method of differential equations~\cite{Kot91a,Kot91b,Kot91c}; for a detailed overview of these and other methods see~\cite{Smi06}.

In this paper discuss the method of differential equations.
In particular, we focus on the fact that a solution to the system of DEs may be easily found as an $\eps$-series when a canonical form of this system is known~\cite{Henn13}.
We consider a general algorithm to find a canonical form of a given system of differential equations in one variable developed by R.N.Lee~\cite{Lee15}.
This method allows (1) to find a Fuchsian form of the system using improved Moser reduction algorithm \cite{Mos59} and then (2) to normalize eigenvalues of the Fuchsian system in all singular points.
If these two steps are successfully completed%
\footnote{In principle, the first step can always be done because Feynman integrals contain only logarithmic singularities. For the discussion of potential complications in the second step see Section~\ref{sec:2}.}
then a transformation which puts the initial system to canonical form may be easily find.
In addition to that this method is focused on systems for Feynman integrals, it also may be successfully used for different problems provided that requirement on particular properties of the initial system are satisfied.

Unfortunately, no implementation of the Lee method was made publicly available so far.
We close this gap and introduce \fuchsia \ --- complete implementation of the method~\cite{Lee15} in the computer algebra system \sage.
Combined together with Laporta algorithm \cite{Lap00} and its implementations~\cite{Smi08,MS12,Lee12,Lee13,SS13,Smi14}, these tools form a powerful tandem for evaluating Feynman integrals.

This paper is organized as follows: in Section \ref{sec:2} we introduce notation and definitions followed by a brief review of the Lee method and related algorithms implemented in \fuchsia.
In Section \ref{sec:3} we describe how to install \fuchsia and use it from different environments, depending on your goal and programming experience.
In Section \ref{sec:4} we discuss limitations and possible extensions of the current implemented and the method in general.


%{\it Analyticity of S-matrix and Fuchsian systems of DE. Reduction to Fuchsian form as an independent problem (Moser~\cite{Mos59},Barkatou~\cite{BP09}, \texttt{super\_reduce} in Maple), but mistreating $\infty$.}

%{\it Integration-by-parts reduction, canonical form (Henn) \cite{Henn13}, Lee algorithm.}

\section{Overview of the Lee method}
\label{sec:2}


\subsection{Notation and definitions}

Let us consider a system of ordinary differential equations (ODEs) of this form:
\begin{equation}
\label{eq:dj}
    \partial_x \V J(x,\eps) = \M A(x,\eps)\,\V J,
\end{equation}
where $\V J(x,\eps)$ is a column-vector of $n$ unknown functions (e.g., master integrals);
$x$ is a free variable;
$\eps$ is an infinitesimally small parameter (e.g., a dimensional regulator in $d=4-2\eps$ dimensions);
$\M A(x,\eps)$ is an $n \times n$ matrix, rational in both $x$ and $\eps$.

In general case $\M A(x,\eps)$ may have a finite number of poles in $x$ at $x\in\{x_k\}$, including a pole at infinity.
Asymptotical behavior of $\M A(x,\eps)$ around these poles can be described as:
\begin{equation}
\label{eq:axeps}
    \M A(x \to x_k,\eps) =
    \begin{cases}
        (\M A_{k0}(\eps) + \M A_{k1}(\eps)\,(x - x_k) + \dots)/(x - x_k)^{1+p_k} & \text{if $x_k\neq\infty$}, \\
        (\M A_{k0}(\eps) + \M A_{k1}(\eps)\,x^{-1} + \dots)\,x^{-1 + p_k} & \text{if $x_k=\infty$},
    \end{cases}
\end{equation}

where $p_k$ is the \textit{Poincar\'e rank} of $\M A(x,\eps)$ at singular point $x=x_k$.
If $p_k=0$, we call $\M A(x,\eps)$ \textit{Fuchsian in $x=x_k$}.
If all $p_k=0$, we call $\M A(x,\eps)$ \textit{Fuchsian}.

Behavior of the system at $x=\infty$ is a bit of special case, but it is essential in the overall reduction process.
One must always keep in mind the $\infty$ point, and treat it on the same footing as other singular points.

\paragraph{Equivalent systems.}
We are interested in transforming system~\eqref{eq:dj} into a simpler form.
For this purpose let's consider a change of basis from $\V J$ into $\V J'$ using linear transformation $\M T(x,\eps)$:
\begin{equation}
  \V J = \M T(x,\eps)\, \V J'.
\end{equation}

This leads to the {\em equivalent system} of ODEs
\begin{equation}
  \partial_x \V J' = \M A'(x,\eps)\,\V J',
\end{equation}
with the new matrix being
\begin{equation}
\label{eq:ta}
  \M A'(x,\eps) = \M T^{-1} \left( \M A \M T - \partial_x \M T \right).
\end{equation}

Generally speaking, transformations $\M T(x,\eps)$ may have arbitrary form, however in the scope of this paper we'll require transformation matrices to be rational in both $x$ and $\eps$.
This restriction guarantees that the equivalent matrix $\M A'(x,\eps)$ and hence all equivalent systems are in the rational form, thus making expansion~\eqref{eq:axeps} possible.

In particular, we'll be using transformation constructed by stepwise application of a \textit{$\M P$-balance between $x=x_1$ and $x=x_2$}, defined like so:
\begin{equation}
\label{eq:bal}
    \mathcal{B}(\M P(\eps), x_1, x_2; x) = \M I - \M P(\eps) + c \frac{x-x_1}{x-x_2} \M P(\eps),
\end{equation}
\begin{equation*}
    c \equiv
    \begin{cases}
        1/x_1 & \text{if $x_1=\infty$}, \\
        x_2 & \text{if $x_2=\infty$}, \\
        1 & \text{otherwise},
    \end{cases}
\end{equation*}
where $\M P(\eps)$ is a projector matrix (that is, $\M P^2=\M P$).

\paragraph{Classification of singularities.}
Following \cite{Mos59}, for a system \eqref{eq:dj} and it's Laurent expansion~\eqref{eq:axeps} we define a rational number
\begin{equation}
\label{eq:mk}
    m_k(\M A) = p_k + \frac{rank(\M A_{k0})}{n}
\end{equation}
as the {\em Moser order} of $\M A(x,\eps)$ at point $x=x_k$.

Equivalent systems do not necessarily have identical Moser orders.
In fact \cite{Mos59} introduces an algorithm that constructs a transformation decreasing $rank(\M A_{k0})$ by at least one (thus reducing $m_k(\M A)$),\footnote{Note that if $rank(\M A_{k0})$ reaches zero, this means that $\M A_{k0}$ is now zero itself, and thus Poincar\'e rank $p_k$ was decreased by at least one.} or certifies that no further order reduction can be achieved.

Let's then denote the {\em minimal order} of $\M A(x,\eps)$ at $x=x_k$ as:
\begin{equation}
\label{eq:muk}
  \mu_k(\M A) = \min m_k(\M A'), \text{ for } \forall \; \M T.
\end{equation}

If $\mu_k(\M A) < m_k(\M A)$ we say that matrix $\M A(x,\eps)$ is {\em Moser-reducible} at $x=x_k$.

With this in mind we can classify a point $x=x_k$ of $\M A(x,\eps)$ as:
\begin{itemize}
  \item {\em regular point}, if $m_k(\M A) = 0$;
  \item {\em apparent singularity}, if $m_k(\M A) > 0$ and $\mu_k(\M A) = 0$;
  \item {\em regular singularity}, if $0 < \mu_k(\M A) \le 1$;
  \item {\em irregular singularity}, if $\mu_k(\M A) > 1$.
\end{itemize}
The matrix $\M A(x,\eps)$ is called {\em Fuchsian} if it does not contain irregular singularities at any value of $x$ including $\infty$.


\subsection{Reduction to canonical form}

In the previous section we have introduced notation and key definitions related to the Fuchsian theory of ODEs.
Now we are ready to review reduction method proposed by Roman Lee in~\cite{Lee15}.
With its help we can construct a rational transformation $\M T(x,\eps)$ which transforms a system of ordinary differential equations with rational coefficients given by the matrix $\M A(x,\eps)$ to the equivalent system given by the matrix $\M M(x,\eps)$ which is Fuchsian and {\em canonical}~\cite{Henn13}, i.e., $\M M(x,\eps) = \eps\, \M S(x)$.
After the canonical form $\M M(x,\eps)$ of the initial system $\M A(x,\eps)$ is found we can easily solve it as a Laurent series in $\eps$ and restore solutions for the initial system $\M A(x,\eps)$ --- which is our ultimate goal --- by solving a linear system of equations.

The whole method is performed in these three steps:

\begin{enumerate}
    \item Given a matrix $\M A(x,\eps)$, find an equivalent system $\M A'(x,\eps)$ and corresponding transformation $\M T(x,\eps)$, such that $\M A'(x,\eps)$ is Fuchsian. We call this step \textit{fuchsification}.
    \item Given a Fuchsian matrix $\M A(x,\eps)$ with eigenvalues of all its residues in $n+m\,\eps$ form, where $n$ is integer, find an equivalent system (along with the transformation) which is still Fuchsian, but with residue eigenvalues being all in the form $k\,\eps$. We call this step \textit{normalization}.
    \item Given a normalized matrix $\M A(x,\eps)$, find an equivalent canonical matrix $\M A'(x)$, i.e. such that $\M A'(x,\eps) = \eps \, \M S'(x)$. We call this step \textit{factorization}.
\end{enumerate}


\subsubsection{Fuchsification}
\label{sec:fuchs}

To \textit{fuchsify} a system~\eqref{eq:dj} is to find an equivalent Fuchsian system.
This, of course, is only possible if $\M A(x,\eps)$ has no irregular singularities, or in other words $\mu_k(\M A)\le1$ for all $k$.\footnote{
    We expect this to be often the case in practice, in particular for ODEs corresponding to Feynman integrals which are known to have only logarithmic singularities, hence be solutions of some Fuchsian ODEs.
}

In the case of a single ODE of order~$n$, the minimal Moser order can be computed explicitly from the power analysis of its coefficients (see generalization of the Fuchs' theorem in~\cite{Mos59}).
This is not possible for ODE systems like~\eqref{eq:dj}.
Instead we have a criterion of Moser-reducibility in the form of:

\textbf{Theorem 1.}
{\em If $m_k(\M A) > 1$ the system \eqref{eq:dj} is Moser-reducible at $x=x_k$ if and only if the polynomial}
\begin{equation}
\label{eq:red_cond}
    \Delta^{r_k} \det\left(\frac{\M A_{k0}}{\Delta} + \M A_{k1} - \lambda \,\M I\right),
\end{equation}
{\em vanishes identically in $\lambda$ at $x=x_k$, where $r_k=\rank(\M A_{k0})$ and $\Delta=x-x_k$ if $x_k\ne\infty$, or $\Delta=1/x$ if $x_k=\infty$.}

If this condition fails then $x=x_k$ is an irregular singularity.

In addition to this criterion we have a method to construct a transformation that lowers Moser order at $x_i$, if the system is at all Moser-reducible at that point (possibly at the expense of increasing Poincar\'e rank $p_j$ at one other point, $x_j$, by one).
This is done by selecting a projector matrix $\M P$ equal to a sum of products of a particular subset of (generalized) eigenvectors of $\M A_{i0}$ and $\M A_{j0}$, and constructing a $\M P$-balance between $x_i$ and~$x_j$.

The reader can find the details of this construction in \cite{Lee15}, but it is important to note that even if the system is Moser-reducible at $x_i$, it is only sometimes possible to construct a transformation that lowers $m_i(\M A)$ without increasing Poincar\'e rank at $x_j$.
Sometimes the best we can do is to choose $x_j$ to be some regular point (with $p_j=-1$), and use a transformation that decreases $m_i(\M A)$ at the expense at increasing $p_j$ to $0$, effectively introducing an apparent singularity where there was none before.\footnote{
    In practice these apparent singularities are not a major problem, since they are subsequentially removed during the normalization step.
    Still, we try no to introduce them if possible to decrease intermediate expression sizes and increase overall performance.
}

With this in mind, to reduce a system to Fuchsian form we need to combine the reducibility check with the Moser rank-lowering transformation in stepwise fashion, like so:

\begin{enumerate}
    \item Select some point $x_k$ with $m_k(\M A) > 1$. If none exist, reduction is complete.
    \item Check if $\M A(x,\eps)$ is reducible at $x=x_k$. If not, fail.
    \item Find a transformation $\M T(x,\eps) = \mathcal{B}(\M P(\eps), x_k, x_j; x)$ that lowers $m_k(\M A)$.
    \item Apply $\M T(x,\eps)$ and repeat from Step 1.
\end{enumerate}

In \fuchsia, this process is implemented by \code{fuchsify} and \code{fuchsify\_by\_blocks} routines; see Section~\ref{sec:usage_py} for their usage.

Finally, let us mention that a similar problem of reducing Poincar\'e ranks and Moser orders of rational matrices was actively studied by Barkatou and co-authors, e.g., see~\cite{BP99}.
Together with Pfl\"ugel they developed algorithms implementing their method~\cite{BP99} and available in the standard \texttt{Maple} package \texttt{DEtools} as \code{moser\_reduce} and \code{super\_reduce} routines.

% TODO: how does our method differ from super-reduce?


\subsubsection{Normalization}
\label{sec:norm}

To \textit{normalize} a Fuchsian system \eqref{eq:dj} with matrix residue eigenvalues of the form $n+m\,\eps$ (where $n$ is integer), is to find an equivalent Fuchsian system with residue eigenvalues of the form $m\,\eps$.

Just like in the previous step, normalizing transformations are found by stepwise application of balance transformations~\eqref{eq:bal}.
We refer the reader to~\cite[p.~11]{Lee15} for the description of how such balances are constructed, but we will note that this transformation is possible due to these two facts:
\begin{itemize}
    \item Given a properly selected projector matrix $\M P(\eps)$, balance $\mathcal{B}(\M P(\eps), x_i, x_j; x)$ shifts one of the eigenvalues of $\M A_{i0}$ by $\pm1$, shifts one of the eigenvalues of $\M A_{j0}$ by $\mp1$, and doesn't change Poincar\'e ranks at any point.
    \item Since the system is Fuchsian, the sum of all it's matrix residues is zero, and thus, the sum of all residue eigenvalues is zero as well.
\end{itemize}
Combining these two facts, we perform normalization by shifting residue eigenvalues by $1$ at each step, until a state is reached where the integer parts of all the eigenvalues are zero.

In \fuchsia, normalization step is implemented by \code{normalize} and \code{fuchsify\_by\_blocks} routines.
See Section~\ref{sec:usage_py} for their usage.

It may happen that after fuchsification we obtain a system the residue eigenvalues of which do not fit the $n+m\,\eps$ form neatly.
In this case it is sometimes possible to rectify the problem by using some non-linear change of variables.
Unfortunately we do not have an automated solution for such cases, and users are expected to find transformations appropriate for their system manually.


\subsubsection{Factorization}
\label{sec:fact}
By {\em factorization} we mean to find a rational transformation $\M T(\eps)$ which transforms a given Fuchsian and normalized matrix to the canonical form.
Let us assume that $\M T(\eps)$ is such a matrix, then an equivalent matrix after transformation, according to eq.~\eqref{eq:ta}, is given by
\begin{equation}
  \M A'(x,\eps) = \eps\, \sum_i \frac{\M A'_i}{x-x_i} = \sum_i \M T^{-1}(\eps) \frac{\M A_i(\eps)}{x-x_i} \M T(\eps),
\end{equation}
or explicitly
\begin{equation}
  \M A'_i = \M T^{-1}(\eps) \frac{\M A_i(\eps)}{\eps} \M T(\eps), \quad \text{for} \quad i=1..k.
\end{equation}
Since $\M A'_i$ is constant for any $\eps$, in order to find components of $n\times n$ matrix $\M T(\eps)$, we write a system of linear equations for some fixed value of $\mu$ at an every singular point $x=x_i$, i.e.,
\begin{equation}
  \frac{\M A_i(\eps)}{\eps} \M T(\eps,\mu) = \M T(\eps,\mu) \frac{\M A_i(\mu)}{\mu},
\end{equation}
where we now treat components of $\M T(\eps,\mu) = \M T(\eps) \; \M T^{-1}(\mu)$ as unknown variables.
The initial transformation we are looking for is then given by $\M T(\eps) = \M T(\eps,\mu_0)$ for some arbitrary chosen number $\mu = \mu_0$, provided that $\M T(\eps, \mu_0)$ is not singular.

In \fuchsia this step is implemented as \code{factorize} routine, see Section~\ref{sec:usage_py}.

\subsubsection{Block-triangular form}
\label{sec:blockreduce}

It is usually happens that a matrix which defines an ODEs is sparse, i.e., has many zeros.
We can use that fact to shuffle the matrix to a block-triangular form.
This can drastically improve fuchsification and normalization steps described in previous sections.
(You will find \code{block\_triangular\_form} routine in \fuchsia which finds a block-triangular form of a given matrix.)
Below we describe an algorithm to fuchsify and normalize a given matrix taking into account its block-triangular form; for more details see~\cite[Section~7]{Lee15}, similar ideas were also discussed in \cite{Git15}.

Let us consider a block-triangular matrix of the form
\begin{equation}
\label{eq:bdiag}
\M A(x,\eps)=
\left(
\begin{matrix}
  \M A_{11} & 0      & 0 & 0 & 0
\\
  \M A_{21} & \M A_{22} & 0 & 0 & 0
\\
  \M A_{31} & \M A_{32} & \M A_{33} & 0 & 0
\\
  \vdots & \cdots & \cdots & \ddots & 0
\\
  \M A_{k1} & \M A_{k2} & \M A_{k3} & \cdots & \M A_{kk}
\end{matrix}
\right)
.
\end{equation}

We start by reducing {\bf diagonal blocks} given by $n_i \times n_i$ matrices $\M A_{ii}(x,\eps)$ to canonical form as described in the previous sections, i.e., by fuchsification, normalization, and factorization.
Since a characteristic polynomial of a block-triangular matrix is a product of characteristic polynomials of its diagonal blocks, i.e.,
\begin{equation}
  \det(\M A(x,\eps)-\lambda \M I) = \det(\M A_{11}(x,\eps) - \lambda\M I) \ldots  \det(\M A_{kk}(x,\eps) - \lambda \M I)
  ,
\end{equation}
after we put each diagonal block to the canonical form the whole matrix became normalized.

Next, we fuchsify {\bf non-diagonal blocks} given by rectangular matrices $\M A_{ij}(x,\eps)$, $i \ne j$.
The idea is to find a new basis for $i$-th block in the form
\begin{equation}
  \V J'_i = \V J'_i + \M T_{ij} \V J,
\end{equation}
where $\M T_{ij}$ is $n_i \times n_j$ matrix with constant coefficients, for details how to find it see \cite[Section 7]{Lee15}.
Our strategy is to loop over $i$ from 2 to $k$ and for every value of $i$ loop over $j$ from $i-1$ to 1.
That allows to preserve normalization and Fuchsian form of already reduced blocks.

In \fuchsia the steps described so far are implemented by \code{fuchsify\_by\_blocks} function.

Finally, in order to factorize a whole matrix we proceed as described in Section~\ref{sec:fact}.


\section{Using \fuchsia}
\label{sec:3}

\subsection{Installation}

To run \fuchsia you need \sage version 7.0 or higher to be installed on your computer.
You can find installation instructions for \sage over at it's website, \url{http://www.sagemath.org}.
\footnote{
    Some \linux distributions have \sage available in their package repositories; we do not recomment using those.
    A number of \maxima releases contain bugs which \fuchsia is sensitive to, and so far the official \sage builds have avoided those releases (unlike a number of \linux distributions).
}

\sage is a free and open-source Computer Algebra System licensed under GPL.
It is written in \python~2.7 and combines together a number of existing open-source mathematical systems and libraries like \texttt{Maxima}, \texttt{Singular}, and others with the goal of providing the best free CAS.
In particular our code heavily relies on the interface to \maxima~\cite{maxima}.

\subsubsection{Installation from PyPI}

To install \fuchsia run the following command in your shell:

\begin{Verbatim}
    \prompt{$}{sage -pip install fuchsia}
\end{Verbatim}

This will install the latest stable version of \fuchsia from the Python Package Index (PyPI) to your \sage environment.

\subsubsection{Installation form sources}

If you are interested in the latest development version then visit \url{https://github.com/gituliar/fuchsia/}.

\subsection{Usage from the command line}

An easy way to use \fuchsia is to run \code{fuchsia.py} shell script, which has the following invocation signature:

\begin{Verbatim}
    \prompt{$}{fuchsia.py <action> <options>}
\end{Verbatim}

where
\begin{itemize}
  \item \code{<action>} is one of the algorithms described in the previous section, i.e., \code{fuchsify}, \code{normalize}, \code{factorize}, or auxiliary action \code{transform}, which applies a user-defined transformation to the given matrix.
  \item \code{<options>} are action-dependent options described in the help message printed with the help of \code{fuchsia.py -h} command.
\end{itemize}

In the following we provide a complete help information printed by \code{fuchsia.py -h}:
\begin{Verbatim}
Fuchsia v16.6.8
Authors: Oleksandr Gituliar, Vitaly Magerya

Usage:
    fuchsia [-hv] [--use-maple] [-f <fmt>] [-l <path>] [-P <path>]
            <command> <args>...

Commands:
    reduce [-x <name>] [-e <name>] [-m <path>] [-t <path>] <matrix>
        find a canonical form of the given matrix

    fuchsify [-x <name>] [-m <path>] [-t <path>] <matrix>
        find a transformation that will transform a given matrix
        into Fuchsian form

    normalize [-x <name>] [-e <name>] [-m <path>] [-t <path>] <matrix>
        find a transformation that will transform a given Fuchsian
        matrix into normalized form

    factorize [-x <name>] [-e <name>] [-m <path>] [-t <path>] <matrix>
        find a transformation that will make a given normalized
        matrix proportional to the infinitesimal parameter

    sort [-m <path>] [-t <path>] <matrix>
        find a block-triangular form of the given matrix

    transform [-x <name>] [-m <path>] <matrix> <transform>
        transform a given matrix using a given transformation

    changevar [-x <name>] [-m <path>] <matrix> <expr>
        transform matrix by susbtituting free variable by a
        given expression

Options:
    -h          show this help message
    -f <fmt>    matrix file format: mtx or m (default: mtx)
    -l <path>   write log to this file
    -v          produce a more verbose log
    -P <path>   save profile report into this file
    -x <name>   use this name for the free variable (default: x)
    -e <name>   use this name for the infinitesimal parameter (default: eps)
    -m <path>   save the resulting matrix into this file
    -t <path>   save the resulting transformation into this file
    --use-maple speed up calculations by using Maple when possible

Arguments:
    <matrix>    read the input matrix from this file
    <transform> read the transformation matrix from this file
    <expr>      arbitrary expression
\end{Verbatim}


\subsection{Usage from \sage or \python}
\label{sec:usage_py}

You can use \fuchsia as a library by starting \sage prompt and importing \texttt{fuchsia} module like this:

\begin{Verbatim}
    \prompt{$}{sage}
    ┌────────────────────────────────────────────────────────────────────┐
    │ SageMath Version 7.1, Release Date: 2016-03-20                     │
    │ Type "notebook()" for the browser-based notebook interface.        │
    │ Type "help()" for help.                                            │
    └────────────────────────────────────────────────────────────────────┘
    \prompt{sage:}{from fuchsia import *}
\end{Verbatim}

You can read the next section for the list of functions you'll get after import, but to give you a feel for the API, let's try reducing a simple matrix.

\begin{Verbatim}
    \prompt{sage:}{x, eps = var("x eps")}
    \prompt{sage:}{M = matrix([}
    \prompt{....:}{  [(2-eps)/x, 0, 0],}
    \prompt{....:}{  [x/(x-1), eps/x, 0],}
    \prompt{....:}{  [(1+2*eps)/x**3, 0, (1+eps)/x/(x+1)]}
    \prompt{....:}{])}
\end{Verbatim}

First, let's see where the singularities of this matrix lie:

\begin{Verbatim}[commandchars=\\!|]
    \prompt!sage:|!singularities(M, x)|
    {-1: 0, 0: 2, 1: 0, +Infinity: 1}
\end{Verbatim}

So, 4 singularites in total, with Poincar\'e rank being 2 at $\code{x}=0$, 1 at $\code{x}=\infty$ and 0 everywhere else.
To get rid of non-zero ranks (thus transforming the system into Fuchsian form) we'll need to \textit{fuchsify} this matrix like so:

\begin{Verbatim}[commandchars=\\!|]
    \prompt!sage:|!Mf, Tf = fuchsify(M, x)|
    \prompt!sage:|!Mf|
    [ -(eps - 2)/x           0                          0]
    [   -1/(x - 1)  (eps -1)/x                          0]
    [(2*eps + 1)/x           0  (eps + 2*x + 3)/(x^2 + x)]
    \prompt!sage:|!singularities(Mf, x)|
    {-1: 0, 0: 0, 1: 0, +Infinity: 0}
\end{Verbatim}

So far, so good. Now, let's take a look at the eigenvalues of \code{Mf} residues:

\begin{Verbatim}
    \prompt{sage:}{[matrix_residue(Mf, x, x0).eigenvalues()}
    \prompt{....:}{  for x0 in [-1, 0, 1, Infinity]]}
    [[-eps - 1, 0, 0],
     [-eps + 2, eps - 1, eps + 3],
     [0, 0, 0],
     [-eps + 1, eps - 2, -2]]
\end{Verbatim}

Many of these eigenvalues are not equal to zero in limit $\code{eps}\to0$, so \code{Mf} is not normalized.
It is however the case that all of the eigenvalues are of the form $n + m*\code{eps}$, so there's a chance we'll be able to normalize \code{Mf}.
Let's try:

\begin{Verbatim}
    \prompt{sage:}{Mn, Tn = normalize(Mf, x, eps)}
    \prompt{sage:}{Mn}
    [-eps/x                                                            ...
    [(4*eps^3 - 8*eps^2 - (4*eps^2 - 6*eps + 3)*x + 5*eps)/((4*eps^3 - ...
    [((2*eps + 1)*x + 3*eps + 1)/(x^2 + x)                             ...
    \prompt{sage:}{[matrix_residue(Mn, x, x0).eigenvalues()}
    \prompt{....:}{  for x0 in [-1, 0, 1, Infinity]]}
    [[-eps, 0, 0],
     [-eps, eps, eps],
     [0, 0, 0],
     [-eps, eps, 0]]
\end{Verbatim}

So, the matrix is normalized, but it grew quite a bit larger.
This happens.
Sometimes it's possible to simplify it a bit like so:

\begin{Verbatim}
    \prompt{sage:}{Ms, Ts = simplify_by_jordanification(Mn, x)}
    \prompt{sage:}{Ms}
    [               -eps/x      0              0]
    [            1/(x - 1)  eps/x              0]
    [1/2*(eps + 1)/(x + 1)      0  eps/(x^2 + x)]
\end{Verbatim}

That's much better.

Finally, we need to \textit{factorize} \code{Ms} to complete the reduction:

\begin{Verbatim}
    \prompt{sage:}{Mr, Tr = factorize(Ms, x, eps)}
    \prompt{sage:}{Mr}
    [         -eps/x      0              0]
    [1/4*eps/(x - 1)  eps/x              0]
    [5/8*eps/(x + 1)      0  eps/(x^2 + x)]
\end{Verbatim}

This is the fully transformed matrix.
As you can see, it is both proportional to \code{eps} and Fuchsian.
To make sure we got everything right, we can double-check the full transformation:

\begin{Verbatim}
    \prompt{sage:}{T = (Tf*Tn*Ts*Tr).simplify_rational()}
    \prompt{sage:}{(Mr - transform(M, x, T)).is_zero()}
    True
\end{Verbatim}

Note that we've used construct \code{(A - B).is\_zero()} to compare matrices instead of the more obvious \code{bool(A == B)}.
This is a \sage idiosyncrasy; the more obvious way compares symbolic matrices only structually.

Of course, you don't need to walk through all these steps yourself every time.
Normally, you just need to call this one function to do all the reduction work:

\begin{Verbatim}
    \prompt{sage:}{MM, TT = canonical_form(M, x, eps)}
    \prompt{sage:}{MM}
    [                          -eps/x      0              0]
    [                 1/4*eps/(x - 1)  eps/x              0]
    [1/4*(9*eps*x + 13*eps)/(x^2 + x)      0  eps/(x^2 + x)]
    \prompt{sage:}{(MM - transform(M, x, TT)).is_zero()}
    True
\end{Verbatim}

Notice that this matrix is slightly more complex than the one we obtained step by step above.
This also happens.
The final form we're computing is not unique, and it will be different depending on the precise sequence of reduction steps you've taken.

Additionally, many of the transformations take a special $seed$ parameter to control the order of operations they perform internally.
By supplying different seeds, you will obtain different results as well.

\subsubsection{Function reference}

\begin{description}[style=nextline]

\functionitem{canonical\_form}{\M M, x, epsilon, seed=0}
Fully reduce a system of equations defined by matrix $\M M$, independent variable $x$ and infinitesimal parameter $epsilon$.
Return a pair of values: the transformed matrix $\M M'$ and the transformation matrix $\M T$.
Raise $FuchsiaError$ if the system is irreducible.

Reduction is performed by first coverting $\M M$ to block-triangular form, then reducing the diagonal blocks via $\F{fuchsify}$, $\F{normalize}$ and $\F{factorize}$, reducing off-diagonal blocks as described in Section~\ref{sec:blockreduce}, and finally factorizing $epsilon$ via $\F{factorize}$.

\functionitem{fuchsify}{\M M, x, seed=0}
Reduce a system defined by matrix $\M M$ and independent variable $x$ to Fuchsian form.
That is, make sure that Poincar\'e ranks of all singularities of the transformed matrix $\M M'$ are $0$.
Return a pair of values: the transformed matrix $\M M'$ and the transformation $\M T$.
If the system is irreducible, raise $FuchsiaError$.

\functionitem{normalize}{\M M, x, epsilon, seed=0}
Transform a Fuchsian system defined by matrix $\M M$, independent variable $x$ and infinitesimal parameter $epsilon$ to a normalized form.
That is, make sure that real parts of eigenvalues of all matrix residues of the transformed matrix $\M M'$ lie in the range $[-1/2, 1/2)$ in the limit $epsilon\to0$.
Return a pair of values: the transformed matrix $\M M'$ and the transformation $\M T$.
If such transformation can not be found, raise $FuchsiaError$.

\functionitem{factorize}{\M M, x, epsilon, seed=0}
Transform a normalized system defined by matrix $\M M$, independent variable $x$ and infinitesimal parameter $epsilon$ so that the
transformed matrix $\M M'$ is proportional to $epsilon$.
Return a pair of values: the transformed matrix $\M M'$ and the transformation $\M T$.
If such transformation can not be found, raise $FuchsiaError$.

\functionitem{simplify\_by\_jordanification}{\M M, x}
Try to simplify a system defined by matrix $\M M$ and independent variable $x$ by constant transformations that transform leading expansion coefficients of $\M M$ into their Jordan forms.
Return a pair of values: the simplified matrix $\M M'$ and the transformation $\M T$.
If none of the attempted transformations reduce the complexity of $\M M$ (as measured by $\F{matrix\_complexity}$), return the original matrix and the identity transformation.

\functionitem{simplify\_by\_factorization}{\M M, x}
Try to simplify a system defined by matrix $\M M$ and independent variable $x$ by a constant transformation that extracts common factors found in $\M M$ (if any).
Return a pair of values: the simplified matrix $\M M'$ and the transformation $\M T$.

\functionitem{matrix\_complexity}{\M M}
This function is used as a measure of matrix complexity by $\F{fuchsify}$ and simplification functions.
Currently it is defined as the length of textual representation of matrix $\M M$.

\functionitem{balance}{\M P, x_1, x_2, x}
Return a \textit{balance} transformation between points $x=x_1$ and $x=x_2$ using projector matrix $\M P$.
See eq.~\eqref{eq:bal} for the definition of a \textit{balance}.

\functionitem{transform}{\M M, x, \M T}
Transform a system defined by matrix $\M M$ and independent variable $x$ using transformation matrix $\M T$ as specified by eq.~\eqref{eq:ta}.
Return the transformed matrix $\M M'$.

\functionitem{balance\_transform}{\M M, \M P, x_1, x_2, x}
Same as $\F{transform}(\M M, x, \F{balance}(\M P, x_1, x_2, x))$, but implemented more efficiently: since the inverse of $\F{balance}(\M P, x_1, x_2, x)$ is $\F{balance}(\M P, x_2, x_1, x)$, this function can avoid a time-consuming matrix inversion operation that $\F{transform}$ must perform.

\functionitem{singularities}{\M M, x}
Find values of $x$ around which matrix $\M M$ has a singularity in $x$.
Return a dictionary with $\{x_i: p_i\}$ entries, where $p_i$ is the Poincar\'e rank of $\M M$ at $x=x_i$.
The set of singular points can include \code{Infinity}, if $\M M$ has a singularity at $x\to\infty$.

\functionitem{matrix\_c0}{\M M, x, x_0, p}
Return the 0-th coefficient of the series expansion of matrix $\M M$ around $x=x_0$, assuming Poincar\'e rank of $\M M$ at that point is $p$.
If $x_0$ is \code{Infinity}, return the coefficient at the highest power of $x$.
In other words, return $\M A_{k0}$ from eq.~\eqref{eq:axeps}.

\functionitem{matrix\_c1}{\M M, x, x_0, p}
Return the 1-th coefficient of the series expansion of matrix $\M M$ around $x=x_0$, assuming Poincar\'e rank of $\M M$ at that point is $p$.
If $x_0$ is \code{Infinity}, return the coefficient at the second-to-highest power of $x$.
In other words, return $\M A_{k1}$ from eq.~\eqref{eq:axeps}.

\functionitem{matrix\_residue}{\M M, x, x_0}
Return matrix residue of matrix $\M M$ at $x=x_0$, assuming that Poincar\'e rank of $\M M$ at $x=x_0$ is $0$.
Return matrix residue at infinity if $x_0$ is \code{Infinity}.

The difference between this function and $\F{matrix\_residue}(\M M, x, x_0, 0)$ is the sign when $x_0$ is \code{Infinity}.

\functionitem{export\_matrix\_to\_file}{filename, \M M, fmt=\code{"mtx"}}
Write matrix $\M M$ to a file $filename$ using MatrixMarket array format if $fmt$ is \code{"mtx"} (which is the default), or Mathematica format if $fmt$ is \code{"m"}.

\functionitem{import\_matrix\_from\_file}{filename}
Read a symbolic matrix from a file $filename$.
Both Mathematica and MatrixMarket array formats are supported.
The exact format will be autodetected.

\functionitem{setup\_fuchsia}{verbosity=0, use\_maple=\code{False}}
Modify some of the \fuchsia inner workings.
In particular, set $verbosity$ to $2$ to enable verbose logging, $1$ to enable normal logging, and $0$ to only log errors.

Set $use\_maple$ to \code{True} to enable usage of \texttt{Maple} to speed up calculations when possible; this may be particularly beneficial for big matrices, and for matrices with singularities at complex points.

\classitem{FuchsiaError}
This is the class of exceptions raised by \fuchsia routines.
It signifies inability to perform requested reduction. 

\end{description}


\section{Summary}
\label{sec:4}

In this paper we have presented \fuchsia, a program for reducing differential equations for Feynman master integrals to canonical form.
\fuchsia is free and open-source: it is build in \python using \maximasage computer algebra system which are available free of charge.
To find the corresponding analytical transformation \fuchsia uses a method proposed by Roman Lee~\cite{Lee15}, which consists of three main computational steps: fuchsification, normalization, and factorization.

In additional, an optimization for block-triangular (or sparse) matrices is also implemented, which allows to reduce relatively large matrices: the reduction of ${74\times74}$ matrix with 20 real and complex singular points and at most $3\times3$ coupled blocks takes about an hour on a laptop with Intel i5 CPU.
In spite of that we still have difficulties to reduce somewhat smaller matrices with complex singular points due to the lack of support of factorization of polynoms with complex coefficients in \maximasage system, which we hope to improve in the next version of the program.
Another promising direction for improvements could be support for multivariate polynomials and symbolic singular points, which would allow to reduce differential equations for multi-scale Feynman master integrals.

\section*{Acknowledgment}

We are gratefully thankful for advanced examples of differential equations provided by Roman Lee and Costas Papadopolous.

This work has been partly supported by Narodowe Centrum Nauki with the Sonata Bis grant DEC-2013/10/E/ST2/00656.
Financial support by DESY during the conference ``Loops and Legs in Quantum Field Theory 2016'' is also gratefully acknowledged. 

\bibliography{fuchsia}

\end{document}
